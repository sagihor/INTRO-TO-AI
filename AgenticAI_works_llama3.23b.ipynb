{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88079a16",
   "metadata": {},
   "source": [
    "# Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105ae079",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e8d156",
   "metadata": {},
   "source": [
    "### Install a Local LLM with Ollama\n",
    "\n",
    "To run this project locally, we will install and use **Ollama**, a lightweight runtime for local large language models.\n",
    "\n",
    "**Download Ollama:**  \n",
    "https://ollama.com/\n",
    "\n",
    "Once installed, you can pull any model you want to run.  \n",
    "Below are a few recommended examples, but you are free to pick any size or model from the Ollama library.\n",
    "\n",
    "ollama pull qwen3:0.6b\n",
    "\n",
    "or\n",
    "\n",
    "ollama pull ibm/granite4:350m\n",
    "\n",
    "or\n",
    "\n",
    "Choose any model you prefer, make sure the model supports tools.\n",
    "Browse available models here:\n",
    "https://ollama.com/library\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42933887",
   "metadata": {},
   "source": [
    "### Python requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e73d984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\users\\idoha\\anaconda3\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: langchain-google-genai in c:\\users\\idoha\\anaconda3\\lib\\site-packages (4.1.3)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\idoha\\anaconda3\\lib\\site-packages (1.2.6)\n",
      "Requirement already satisfied: mcp in c:\\users\\idoha\\anaconda3\\lib\\site-packages (1.25.0)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\idoha\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langgraph) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langgraph) (0.3.1)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langgraph) (2.12.5)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langchain-google-genai) (1.56.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langchain-core) (0.6.1)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langchain-core) (6.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langchain-core) (0.12.0)\n",
      "Requirement already satisfied: anyio>=4.5 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from mcp) (4.12.1)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from mcp) (0.4.3)\n",
      "Requirement already satisfied: httpx>=0.27.1 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from mcp) (0.28.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from mcp) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from mcp) (2.12.0)\n",
      "Requirement already satisfied: pyjwt[crypto]>=2.10.1 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from mcp) (2.10.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from mcp) (0.0.21)\n",
      "Requirement already satisfied: pywin32>=310 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from mcp) (311)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from mcp) (3.1.2)\n",
      "Requirement already satisfied: starlette>=0.27 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from mcp) (0.50.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.1 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from mcp) (0.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from mcp) (0.40.0)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langchain-ollama) (0.6.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from anyio>=4.5->mcp) (3.4)\n",
      "Requirement already satisfied: google-auth[requests]<3.0.0,>=2.45.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.47.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.31.0)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from httpx>=0.27.1->mcp) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from httpx>=0.27.1->mcp) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.1->mcp) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (2.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from jsonschema>=4.20.0->mcp) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from jsonschema>=4.20.0->mcp) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from jsonschema>=4.20.0->mcp) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from jsonschema>=4.20.0->mcp) (0.30.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.41.5)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from pydantic-settings>=2.5.2->mcp) (0.21.0)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from pyjwt[crypto]>=2.10.1->mcp) (41.0.3)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from uvicorn>=0.31.1->mcp) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn>=0.31.1->mcp) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp) (1.15.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.26.16)\n",
      "Requirement already satisfied: pycparser in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp) (2.21)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\idoha\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph langchain-google-genai langchain-core mcp langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182e2139",
   "metadata": {},
   "source": [
    "## 1. Define FastMCP Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f01bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from color_blocks_state import color_blocks_state, init_goal_for_search\n",
    "from heuristics import init_goal_for_heuristics, advanced_heuristic\n",
    "from search import search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3eeb67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp.server.fastmcp import FastMCP\n",
    "import math\n",
    "\n",
    "# Initialize FastMCP\n",
    "mcp = FastMCP(\"Unified Solver\")\n",
    "\n",
    "@mcp.tool()\n",
    "def calculate_sum(a: float, b: float) -> float:\n",
    "    \"\"\"Calculates the sum of two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@mcp.tool()\n",
    "def calculate_power(base: float, exponent: float) -> float:\n",
    "    \"\"\"Calculates the power of a base number.\"\"\"\n",
    "    return math.pow(base, exponent)\n",
    "\n",
    "# TO DO: Add more tools as needed for your application\n",
    "@mcp.tool()\n",
    "def solve_search_cost(start_state: str, goal_state: str) -> int:\n",
    "    \"\"\"Compute the optimal solution cost. \n",
    "    start_state: string like '(5,2),(1,3),(9,22),(21,4)'\n",
    "    goal_state: string like '2,22,4,3' (ONLY numbers and commas)\"\"\"\n",
    "   \n",
    "    #removal of chars that the model seems to add\n",
    "    clean_goal = goal_state.replace(\"(\", \"\").replace(\")\", \"\").replace(\" \", \"\")\n",
    "    \n",
    "    init_goal_for_search(clean_goal)\n",
    "    init_goal_for_heuristics(clean_goal)\n",
    "    start = color_blocks_state(start_state)\n",
    "    path = search(start, advanced_heuristic)\n",
    "\n",
    "    if path is None: return -1\n",
    "    return len(path) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e14fe879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(solve_search_cost(\"(5,2),(1,3),(9,22),(21,4)\", \"2,22,4,3\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc32e06d",
   "metadata": {},
   "source": [
    "## 2. LLM + MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e9ea7",
   "metadata": {},
   "source": [
    "### 2.1. Global instance of our LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "420c2293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "#from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "# Choose your model here, can be Ollama or Google Gemini\n",
    "# Can also switch between different model sizes as needed\n",
    "# model = \"qwen3:0.6b\"\n",
    "#model = \"ibm/granite4:350m\"\n",
    "model = \"llama3.2:3b\"\n",
    "global_llm = ChatOllama(model=model, temperature=0.0)\n",
    "\n",
    "# SETUP API KEY if using Google Gemini\n",
    "#os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_GOOGLE_API_KEY_HERE\"\n",
    "\n",
    "# model = \"gemini-2.5-flash\"\n",
    "# model = \"gemini-2.5-flash-lite\"\n",
    "# global_llm = ChatGoogleGenerativeAI(model=model, temperature=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d5dee",
   "metadata": {},
   "source": [
    "### 2.2. Our agent graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dba39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, START, StateGraph\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver # Optional: For saving graph state\n",
    "import uuid\n",
    "\n",
    "\n",
    "def create_agent_graph(sys_msg, tools):\n",
    "    \"\"\" Creates a LangGraph StateGraph with the given tools integrated.\"\"\"\n",
    "\n",
    "    llm = global_llm\n",
    "\n",
    "    if tools:\n",
    "        llm_with_tools = llm.bind_tools(tools)\n",
    "    else:\n",
    "        llm_with_tools = llm\n",
    "\n",
    "    # Node\n",
    "    def assistant(state: MessagesState):\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                llm_with_tools.invoke([sys_msg] + state[\"messages\"], think=False)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Graph\n",
    "    builder = StateGraph(MessagesState)\n",
    "\n",
    "    # Define the basic graph structure\n",
    "    builder.add_node(\"assistant\", assistant)\n",
    "    builder.add_edge(START, \"assistant\")\n",
    "\n",
    "    if tools:\n",
    "        builder.add_node(\"tools\", ToolNode(tools))  \n",
    "        builder.add_conditional_edges(\n",
    "            \"assistant\",\n",
    "            tools_condition,\n",
    "        )\n",
    "        builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "    react_graph = builder.compile()\n",
    "\n",
    "    return react_graph\n",
    "\n",
    "\n",
    "async def run_agent(prompt, tools, sys_msg=\"\"):\n",
    "\n",
    "    sys_msg = SystemMessage(content=sys_msg)\n",
    "\n",
    "    # 3. Create Graph\n",
    "    graph = create_agent_graph(sys_msg, tools)\n",
    "    \n",
    "    unique_id = str(uuid.uuid4())\n",
    "    # 4. Run (using ainvoke for async tools)\n",
    "    config = {\"configurable\": {\"thread_id\": unique_id}}\n",
    "    result = await graph.ainvoke({\"messages\": [HumanMessage(content=prompt)]}, config)\n",
    "\n",
    "    last_msg = result[\"messages\"][-1].content\n",
    "\n",
    "    # Extract tool names and outputs\n",
    "    tools_used = []\n",
    "    tools_output = []\n",
    "    \n",
    "    # Parsing logic specific to your request\n",
    "    for msg in result[\"messages\"]:\n",
    "        # In LangChain, tool calls are usually in 'tool_calls' attribute of AIMessage\n",
    "        # or 'name' attribute if it is a ToolMessage\n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "             for tool_call in msg.tool_calls:\n",
    "                tools_used.append(tool_call['name'])\n",
    "        \n",
    "        if msg.type == 'tool':\n",
    "            tools_output.append(msg.content)\n",
    "\n",
    "    return last_msg, tools_used, tools_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73790d1f",
   "metadata": {},
   "source": [
    "### 2.3. Tools that run spacific agent (with tools and without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6678099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@mcp.tool()\n",
    "async def ask_agent_with_tools(prompt: str) -> str: # specifically return str to avoid model mistakes\n",
    "    \"\"\" Runs the agent with access to tools. Expects a single string prompt. \"\"\"\n",
    "    tools = [solve_search_cost]\n",
    "    results = await run_agent(prompt, tools)\n",
    "    return results[0]\n",
    "\n",
    "@mcp.tool()\n",
    "async def ask_agent_without_tools(prompt: str) -> str:  # specifically return str to avoid model mistakes\n",
    "    \"\"\" Runs the agent without access to tools. Expects a single string prompt. \"\"\"\n",
    "    results = await run_agent(prompt, [])\n",
    "    return results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88f6ab0",
   "metadata": {},
   "source": [
    "## 3. Run the Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e1fbfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: **Agent with Tools Output:** 6\n",
      "**Agent without Tools Output:** 10\n",
      "**Comparison:** The agent with tools uses an optimal A* algorithm, while the other estimates. The agent with tools found the minimum number of moves required to transform the start state into the goal state, which is 6. In contrast, the agent without tools estimated a higher cost of 10.\n",
      "Tools Used: ['ask_agent_with_tools', 'ask_agent_without_tools']\n",
      "Tool Outputs: ['The optimal solution cost (minimum number of moves) from start to goal is 6.', 'To find the minimum number of moves required to transform the start state into the goal state, we can use a breadth-first search (BFS) algorithm.\\n\\nThe start state is: \"(5,2), (1,3), (9,22), (21,4)\"\\n\\nThe goal state is: \"2, 22, 4, 3\"\\n\\nWe will transform each pair of coordinates into the desired order by swapping them. We can use a queue to keep track of the states to be explored.\\n\\nHere\\'s the BFS algorithm:\\n\\n1. Start with the initial state: \"(5,2), (1,3), (9,22), (21,4)\"\\n2. Create a queue and add the initial state to it.\\n3. While the queue is not empty:\\n   - Dequeue a state from the queue.\\n   - For each pair of coordinates in the dequeued state:\\n     - If the pair is in the correct order (i.e., \"2, 22, 4, 3\"), add the next state to the queue by swapping the pairs.\\n     - Otherwise, continue with the rest of the pairs.\\n   - Add any new states to the queue that have not been visited before.\\n\\nAfter running the BFS algorithm, we find that the minimum number of moves required to transform the start state into the goal state is 6:\\n\\n1. Swap (5,2) and (21,4): \"(21,4), (5,2), (9,22), (1,3)\"\\n2. Swap (1,3) and (9,22): \"(21,4), (5,2), (1,22), (3)\"\\n3. Swap (5,2) and (1,22): \"(21,4), (1,22), (5,2), (3)\"\\n4. Swap (21,4) and (3): \"(21,3), (1,22), (5,2), (4)\"\\n5. Swap (21,3) and (9,22): \"(21,3), (9,22), (1,22), (5,2)\"\\n6. Swap (21,3) and (2,22): \"(21,2), (9,22), (1,22), (5,2)\"\\n\\nThe final state is: \"2, 22, 4, 3\"\\n\\nTherefore, the optimal solution cost (minimum number of moves) from start to goal is 6.']\n"
     ]
    }
   ],
   "source": [
    "sys_msg = \"\"\"\n",
    "    You are a Research Supervisor. You must evaluate two assistants on a Color-Blocks search problem.\n",
    "    \n",
    "    CRITICAL: When calling the tools, you MUST pass the full problem description including:\n",
    "    Start state: \"(5,2),(1,3),(9,22),(21,4)\"\n",
    "    Goal state: \"2,22,4,3\"\n",
    "\n",
    "    OUTPUT FORMAT RULES:\n",
    "    You MUST provide your final response in this exact template:\n",
    "    \n",
    "    **Agent with Tools Output:** [Insert their cost here]\n",
    "    **Agent without Tools Output:** [Insert their cost here]\n",
    "    \n",
    "    **Comparison:** [Explain why the costs differ. Note that the agent with tools uses an optimal A* algorithm, while the other estimates.]\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "    Compare the two assistants on this Color-Blocks search question:\n",
    "    Start state: \"(5,2),(1,3),(9,22),(21,4)\"\n",
    "    Goal state: \"2,22,4,3\"\n",
    "    Question: What is the optimal solution cost (minimum number of moves) from start to goal?\n",
    "\"\"\"\n",
    "\n",
    "tool_list = [ask_agent_with_tools, ask_agent_without_tools]\n",
    "\n",
    "response, tools, outputs = await run_agent(prompt, tool_list, sys_msg)\n",
    "print(f\"Response: {response}\")\n",
    "print(f\"Tools Used: {tools}\")\n",
    "print(f\"Tool Outputs: {outputs}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
